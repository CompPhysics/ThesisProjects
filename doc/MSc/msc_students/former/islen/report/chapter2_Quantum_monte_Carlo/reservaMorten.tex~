\chapter{Quantum  Monte Carlo methods}\label{QMC}

Most physical problems of interest in atomic, molecular and solid state 
physics consist of a number of 
interacting electrons and ions. 
The total number of particles $N$ is usually sufficiently large
that an exact solution cannot be found. 
Typically, 
the expectation value for a chosen hamiltonian for a system of 
$N$ particles is
\be
   \langle H \rangle =
   \frac{\int d{\bf R}_1d{\bf R}_2\dots d{\bf R}_N
         \Psi^{\ast}({\bf R_1},{\bf R}_2,\dots,{\bf R}_N)
          H({\bf R_1},{\bf R}_2,\dots,{\bf R}_N)
          \Psi({\bf R_1},{\bf R}_2,\dots,{\bf R}_N)}
        {\int d{\bf R}_1d{\bf R}_2\dots d{\bf R}_N
        \Psi^{\ast}({\bf R_1},{\bf R}_2,\dots,{\bf R}_N)
        \Psi({\bf R_1},{\bf R}_2,\dots,{\bf R}_N)},
\ee
an in general intractable problem.
Controlled and well understood approximations are sought to 
reduce the complexity to a tractable level. Once
the equations are solved, a large number of properties 
may be calculated from the wave function. 
Errors or approximations made in obtaining the
wave function will be manifest in any property derived from the wave function. 
Where high accuracy is required, considerable attention must be paid to
the derivation of the wave function and any approximations made. 


\section{Variational monte carlo}

The variational monte carlo method derives from the variational principle of quantum mechanics and it states that \emph{the energy of a trial wave function will be greater than or equal to the energy of the exact wave function}. In order to obtain a desired degree of accuracy mmmmmmmmm



% % % % % \section{Local energy}
% % % % % 
% % % % % $$\sum_{i=1}^{N} -\frac{1}{2} $$
% % % % %  RESERVA NNNNNNNNNNNNNNNNNNNNNNNNNNN
            %%%%%%%%%%%%%%%%5MMMMMMMMMMMMMMMMMMMMMMMMMMM
% % % % % 
% % % % % The key idea behind the variational monte Carlo method derive from the ability to 
% % % % % describe the average property $\Op{O}$ as a average over an assambly
% % % % % 
% % % % % $$\obs{E}_L = \frac{\int \PsiT \Op{H}(\bfv{R}) \PsiT d\bfv{R}}{\int \PsiT d\bfv{R}}$$
% % % % % 
% % % % % Eq.~(\ref{eq:multidimvmc}) is a multidimensional integral. As such, Monte Carlo 
% % % % % methods are ideal for obtaining expectation values of quantum mechanical operators.
% % % % % Our problem is that we do not know the exact wavefunction $\Psi({\bf r}_1,..,{\bf
% % % % % r}_A,\alpha_1,..,\alpha_N)$.
% % % % % We can circumvent this problem by introducing a function which depends on selected
% % % % % variational parameters.
% % % % % This function should capture essential 
% % % % % features of the system under consideration. With such a trial wave function we can
% % % % % then attempt to perform a
% % % % % variational calculation of various observables, using Monte Carlo methods for 
% % % % % solving Eq.~(\ref{eq:multidimvmc}). 



\section{Trial wave functions}


\section{First Encounter with the Variational Monte Carlo Method}

The required Monte Carlo techniques for variational Monte Carlo are conceptually
simple, but the practical application may turn out to be rather 
tedious and complex, relying on a good starting point for the 
variational wave functions. These wave functions should include as
much as possible of the inherent physics to the problem, since they
form the starting point for a variational calculation of the expectation
value of the hamiltonian $H$. Given a hamiltonian $H$ and a trial
wave function $\Psi_T$, the variational principle states that
the expectation value of $\langle H \rangle$, defined through Postulate III
\be
   \langle H \rangle =
   \frac{\int d{\bf R}\Psi^{\ast}_T({\bf R})H({\bf R})\Psi_T({\bf R})}
        {\int d{\bf R}\Psi^{\ast}_T({\bf R})\Psi_T({\bf R})},
      \label{eq:variation}
\ee
is an upper bound to the ground state energy $E_0$ of the hamiltonian $H$, that
is 
\be 
    E_0 \le \langle H \rangle .
\ee

To show this, we note first that the trial wave function can be expanded
in the eigenstates of the hamiltonian since they form a complete set, see again
Postulate III,
\be
   \Psi_T({\bf R})=\sum_i a_i\Psi_i({\bf R}),
\ee
and assuming the set of eigenfunctions to be normalized, insertion of the 
latter equation in Eq.~(\ref{eq:variation}) results in
\be
   \langle H \rangle =
   \frac{\sum_{mn}a_m^{\ast}a_n\int d{\bf R}\Psi_m^{\ast}({\bf R})H({\bf
R})\Psi_n({\bf R})}
        {\sum_{mn}a_m^{\ast}a_n\int d{\bf R}\Psi^{\ast}_m({\bf R})\Psi_n({\bf R})}
=
   \frac{\sum_{mn}a_m^{\ast}a_n\int d{\bf R}\Psi_m^{\ast}({\bf R})E_n({\bf
R})\Psi_n({\bf R})}
        {\sum_{n}a^2_n},
\ee
which can be rewritten
as
\be
   \frac{\sum_{n}a^2_n E_n}
        {\sum_{n}a^2_n} \ge E_0. 
\ee
In general, the integrals involved in the calculation of various  expectation
values  are multi-dimensional ones. Traditional integration methods
such as the Gauss-Legendre will not be adequate for say the 
computation of the energy of a many-body system.
The fact that we need to sample over  a multi-dimensional density and that
the probability density is to be normalized by the division of the 
norm of the wave function, suggests that e.g., the Metropolis algorithm
may be appropriate.

We could briefly summarize the above variational procedure in the 
following three steps.
\begin{enumerate}
\item Construct first a trial wave function $\psi_T({\bf R};\alpha)$, 
for say a many-body
system consisting of $N$ particles located at positions
${\bf R=(R_1,\dots ,R_N)}$. The trial wave function depends
on $\alpha$ variational parameters ${\bf \alpha=(\alpha_1,\dots ,\alpha_N)}$.
\item Then we evaluate the expectation value of the hamiltonian $H$ 
\[
   \langle H \rangle =
   \frac{\int d{\bf R}\Psi^{\ast}_{T}({\bf R};\alpha)H({\bf R})
         \Psi_{T}({\bf R};\alpha)}
        {\int d{\bf R}\Psi^{\ast}_{T}({\bf R};\alpha)\Psi_{T}({\bf R};\alpha)}.
\]
\item Thereafter we vary $\alpha$ according to some minimization
algorithm and return to the first step.
\end{enumerate}
The above loop stops when we reach the minimum of the energy according
to some specified criterion. 
In most cases, a wave function has only small values in large parts of 
configuration space, and a straightforward procedure which uses
homogenously distributed random points in configuration space 
will most likely lead to poor results. This may suggest that some kind
of importance sampling combined with e.g., the Metropolis algorithm 
may be  a more efficient way of obtaining the ground state energy.
The hope is then that those regions of configurations space where
the wave function assumes appreciable values are sampled more 
efficiently. 

The tedious part in a variational Monte Carlo calculation is the search for the
variational
minimum. A good knowledge of the system is required in order to carry out
reasonable variational Monte Carlo calculations. This is not always the case, 
and often variational Monte Carlo calculations 
serve rather as the starting
point for so-called diffusion Monte Carlo calculations. Diffusion Monte Carlo is a
way of
solving exactly the many-body Schr\"odinger equation by means of 
a stochastic procedure. A good guess on the binding energy
and its wave function is however necessary. 
A carefully performed variational Monte Carlo calculation can aid in this context. 
Diffusion Monte Carlo is discussed in depth in chapter \ref{chap:advancedqmc}.

\section{Variational Monte Carlo for quantum mechanical systems} 
The variational quantum Monte Carlo  has been widely applied 
to studies of quantal systems. Here we expose its philosophy and present
applications and critical discussions.

The recipe, as discussed in chapter \ref{chap:mcint} as well, consists in choosing 
a trial wave function
$\psi_T({\bf R})$ which we assume to be as realistic as possible. 
The variable ${\bf R}$ stands for the spatial coordinates, in total 
$3N$ if we have $N$ particles present. 
The trial wave function serves then, following closely 
the discussion on importance sampling in section \ref{sec:mcintegration}, as
a mean to define the quantal probability distribution 
\be
   P({\bf R};\alpha)= \frac{\left|\psi_T({\bf R};\alpha)\right|^2}{\int
\left|\psi_T({\bf R};\alpha)\right|^2d{\bf R};\alpha}.
\ee
This is our new probability distribution function  (PDF). 

The expectation value of the energy Hamiltonian
is given by
\be
   \langle \Op{H} \rangle =
   \frac{\int d{\bf R}\Psi^{\ast}({\bf R})H({\bf R})\Psi({\bf R})}
        {\int d{\bf R}\Psi^{\ast}({\bf R})\Psi({\bf R})},
\ee
where $\Psi$ is the exact eigenfunction. Using our trial
wave function we define a new operator, 
the so-called  
local energy, 
\be
   \Op{E}_L({\bf R};\alpha)=\frac{1}{\psi_T({\bf R};\alpha)}\Op{H}\psi_T({\bf
R};\alpha),
   \label{eq:locale1}
\ee
which, together with our trial PDF allows us to compute the expectation value of the
local energy
\be
  \langle E_L(\alpha) \rangle =\int P({\bf R};\alpha)\Op{E}_L({\bf R};\alpha) d{\bf R}.
  \label{eq:vmc1}
\ee
This equation expresses the variational Monte Carlo approach.
We compute this integral for a set of values of $\alpha$ and possible trial wave
functions and search for
the minimum of the function $E_L(\alpha)$. 
If the trial wave function is close to the exact wave function, then $\langle
E_L(\alpha) \rangle$ should approach
$\langle \Op{H} \rangle$. Eq.~(\ref{eq:vmc1}) is solved using techniques from Monte
Carlo integration, see the discussion below.
For most hamiltonians, $H$ is a sum of kinetic energy, involving 
a second derivative, and a momentum independent and spatial dependent potential. 
The contribution from the potential term is hence just the 
numerical value of the potential. A typical Hamiltonian reads thus
\begin{equation}
  \Op{H} = - \frac {\hbar^2}{2m} \sum_{i=1}^N \nabla_i^2 + \sum_{i=1}^N
V_{\mathrm{onebody}}({\bf r}_i) 
  + \sum_{i<j}^N V_{\mathrm{int}}(\mid{\bf r}_i -{\bf r}_j \mid ). 
\end{equation}
where the sum runs over all particles $N$. We have included both a onebody potential 
$V_{\mathrm{onebody}}({\bf r}_i)$ which acts on one particle at the time and a twobody
interaction $V_{\mathrm{int}}(\mid{\bf r}_i -{\bf r}_j \mid )$ which acts between
two particles
at the time. We can obviously extend this to more complicated three-body and/or
many-body forces as well.
The main contributions to the energy of physical systems is largely dominated by
one- and two-body
forces. We will therefore limit our attention to such interactions only.

Our local energy operator becomes then 
\be
   \Op{E}_L({\bf R};\alpha)=\frac{1}{\psi_T({\bf R};\alpha)}\left(- \frac
{\hbar^2}{2m} \sum_{i=1}^N \nabla_i^2+ \sum_{i=1}^N 
V_{\mathrm{onebody}}({\bf r}_i) + \sum_{i<j}^N V_{\mathrm{int}}(\mid{\bf r}_i -{\bf
r}_j \mid )\right)\psi_T({\bf R};\alpha),
\ee
resulting in
\be
   \Op{E}_L({\bf R};\alpha)=\frac{1}{\psi_T({\bf R};\alpha)}\left(- \frac
{\hbar^2}{2m} \sum_{i=1}^N \nabla_i^2\right)\psi_T({\bf R};\alpha) 
  + \sum_{i=1}^N V_{\mathrm{onebody}}({\bf r}_i) + \sum_{i<j}^N
V_{\mathrm{int}}(\mid{\bf r}_i -{\bf r}_j \mid ),
\ee
The numerically time-consuming part in the variational Monte Carlo calculation is
the evaluation of the kinetic energy term.
The potential energy, as long as it has a simple $r$-dependence adds only a simple
term to the local energy operator.


In our discussion below, we base     
our numerical Monte Carlo solution on the Metropolis
algorithm. The implementation is rather similar to the
one discussed in connection with the Ising model, the main
difference residing in the form of the PDF. The main test to be performed is
a ratio of probabilities. Suppose we are attempting to move from 
position ${\bf R}$ to ${\bf R'}$. Then we perform the following two tests.  
\begin{enumerate}
 \item If 
   \[ \frac{P({\bf R}';\alpha)}{P({\bf R};\alpha)} > 1, \]
    where ${\bf R}'$ is the new position, the new step is accepted, or
  \item 
       \[ r\le  \frac{P({\bf R}';\alpha)}{P({\bf R};\alpha)}, \]
  where $r$ is random number generated with uniform PDF such that
  $r\in [0,1]$, the step is also accepted.
\end{enumerate}
In the Ising model we were flipping one spin at the time. Here we change
the position of say a given particle to a trial position 
${\bf R}'$, and then evaluate the ratio between two probabilities.
We note again that we do not need to evaluate 
the norm\footnote{This corresponds to the  partition function 
$Z$ in statistical physics.} 
$\int \left|\psi_T({\bf R};\alpha)\right|^2d{\bf R}$ (an in general
impossible task), 
since we are only computing ratios. 

When writing a variational Monte Carlo program, one should always prepare in advance
the required formulae for the local energy $E_L$ 
in Eq.\  (\ref{eq:vmc1}) 
and the wave function needed in order to compute the 
ratios of probabilities in the Metropolis algorithm.
These two functions are almost called as often as a random
number generator, and care should therefore be exercised 
in order to prepare an efficient code. 


If we now focus on the Metropolis algorithm and the Monte Carlo 
evaluation of Eq.~(\ref{eq:vmc1}), a more detailed algorithm is   
as follows
       \begin{itemize}
          \item Initialisation: Fix the number of Monte Carlo steps and 
                thermalization steps. Choose an initial ${\bf R}$ and
                variational parameters $\alpha$ and 
                calculate
                $\left|\psi_T({\bf R};\alpha)\right|^2$. 
                Define also the value 
                of the stepsize to be used when moving from one value of 
                ${\bf R}$ to a new one.
          \item Initialise the energy and the variance.
          \item Start the Monte Carlo calculation with a loop over a given number of
Monte Carlo cycles
                \begin{enumerate}
                  \item Calculate  a trial position  ${\bf R}_p={\bf R}+r*step$
                        where $r$ is a random variable $r \in [0,1]$.
                  \item Use then the Metropolis algorithm to accept
                        or reject this move by calculating the ratio
                        \[
                           w = P({\bf R}_p)/P({\bf R}).
                        \]
                        If $w \ge s$, where $s$ is a random number
                          $s \in [0,1]$, 
                          the new position is accepted, else we 
                          stay at the same place.
                  \item If the step is accepted, then we set 
                        ${\bf R}={\bf R}_p$. 
                  \item Update the local energy and the variance.
                 \end{enumerate}
          \item When the Monte Carlo sampling is finished, 
we calculate the mean energy and the standard deviation. Finally,
we may print our results to a specified file.
      \end{itemize}

Note well that the way we choose the next step ${\bf R}_p={\bf R}+r*step$ is not
determined 
by the wave function. The wave function enters only the determination of the ratio
of probabilities,
similar to the way we simulated systems in statistical physics. This means in turn
that our sampling of
points may not be very efficient. We will return to an efficient sampling 
of integration points in our discussion of diffusion Monte Carlo in chapter
\ref{chap:advancedqmc}.
This leads to the concept of importance sampling.
As such, we limit ourselves in this chapter to the simplest possible form of the
Metropolis algorithm, 
and relegate
both importance sampling and advanced optimization techniques to chapter
\ref{chap:advancedqmc}.

The best way however to understand the above algorithm and a specific method is to
study selected examples.



\section{Variational monte Carlo}


The variational quantum Monte Carlo (VMC) has been widely applied 
to studies of quantal systems. The recipe consists in choosing 
a trial wave function $\Psi_T({\bf R})$ which we assume to be as realistic as possible. 
The variable ${\bf R}$ stands for the spatial coordinates, in total 
$dN$ if we have $N$ particles present. The variable $d$ is the dimension
of the system. 
The trial wave function serves then as
a mean to define the quantal probability distribution 
\be
   P({\bf R})= \frac{\left|\Psi_T({\bf R})\right|^2}{\int \left|\Psi_T({\bf R})\right|^2d{\bf R}}.
\ee
This is our new probability distribution function (PDF). 

The expectation value of the energy $E$
is given by
\be
   \langle E \rangle =
   \frac{\int d{\bf R}\Psi^{\ast}({\bf R})H({\bf R})\Psi({\bf R})}
        {\int d{\bf R}\Psi^{\ast}({\bf R})\Psi({\bf R})},
\ee
where $\Psi$ is the exact eigenfunction. Using our trial
wave function we define a new operator, 
the so-called  
local energy, 
\be
   E_L({\bf R})=\frac{1}{\Psi_T({\bf R})}H\Psi_T({\bf R}),
   \label{eq:locale1}
\ee
which, together with our trial PDF allows us to rewrite the 
expression for the energy as
\be
  \langle H \rangle =\int P({\bf R})E_L({\bf R}) d{\bf R}.
  \label{eq:vmc1}
\ee
This equation expresses the variational Monte Carlo approach.
For most hamiltonians, $H$ is a sum of kinetic energy, involving 
a second derivative, and a momentum independent potential. 
The contribution from the potential term is hence just the 
numerical value of the potential.

Using the Metropolis algorithm and the Monte Carlo 
evaluation of Eq.~(\ref{eq:vmc1}), a detailed algorithm is   
as follows
\begin{itemize}
\item Initialisation: Fix the number of Monte Carlo steps and 
thermalization steps. Choose an initial ${\bf R}$ and
variational parameters $\alpha$ and 
calculate
$\left|\Psi_T^{\alpha}({\bf R})\right|^2$. 
Define also the value 
of the stePsize to be used when moving from one value of 
${\bf R}$ to a new one.
\item Initialise the energy and the variance.
\item Start the Monte Carlo calculation 
\begin{enumerate}
  \item Thermalise first.
  \item Thereafter start your Monte carlo sampling.
  \item Calculate  a trial position  ${\bf R}_p={\bf R}+r*step$
        where $r$ is a random variable $r \in [0,1]$.
  \item Use then the Metropolis algorithm to accept
        or reject this move by calculating the ratio
        \[
            w = P({\bf R}_p)/P({\bf R}).
        \]
        If $w \ge s$, where $s$ is a random number
          $s \in [0,1]$, 
          the new position is accepted, else we 
          stay at the same place.
  \item If the step is accepted, then we set 
        ${\bf R}={\bf R}_p$. 
  \item Update the local energy and the variance.
  \end{enumerate}
\item When the Monte Carlo sampling is finished, 
we calculate the mean energy and the standard deviation.
\end{itemize}




