\documentclass[../main.tex]{subfiles}
 
\begin{document}
\begin{appendices}
%\chapter{Appendix}

\chapter{Calculations of Closed Form Expressions}
\section{Two-body quantum dots}\label{sec:ClosedFormTwo}
To find an expression for the local energy we need to find the Laplacian of the trial wave function
\begin{equation}\label{eq:trial}
   \psi_{T}({\bf r_1},{\bf r_2}) = 
   C\exp{\left(-\alpha\omega(r_1^2+r_2^2)/2\right)}
   \exp{\left(\frac{ar_{12}}{(1+\beta r_{12})}\right)}.
\end{equation}
We define 
\begin{align}
    u =& -\alpha\omega(r_1^2+r_2^2)/2\\
    v =& \frac{ar_{12}}{(1+\beta r_{12})}
\end{align}
Then we have 
\begin{align}
    \nabla_1 \exp(u) = -\alpha\omega \mathbf{r}_1\exp(u).
\end{align}
For $\nabla_1 \exp(v)$ we look at the first component of the gradient
\begin{align}\label{eq: chainDeriv}
\begin{split}
    \frac{\partial}{\partial x_1} \exp(v(r_{12})) =& \frac{\partial r_{12}}{\partial x_1}\frac{\partial}{\partial r_{12}} \exp(v(r_{12}))\\
    =& \frac{(x_1 - x_2)}{r_{12}} \frac{\partial}{\partial r_{12}} \exp(v(r_{12}))\\
    =& \frac{(x_1 - x_2)}{r_{12}} \frac{a}{(1+\beta r_{12})^2}\exp(v(r_{12})),
\end{split}
\end{align}
which gives 
\begin{align}
    \nabla_1 \exp(v) = \frac{(\mathbf{r}_1 - \mathbf{r}_2)}{r_{12}} \frac{a}{(1+\beta r_{12})^2}\exp(v).
\end{align}
For the second particle we have 
\begin{align}
    \nabla_2 \exp(u) =& -\alpha\omega \mathbf{r}_2\exp(u)\\
    \nabla_2 \exp(v) =& -\nabla_1 \exp(v).
\end{align}
The gradients for the full wave function are then 
\begin{align}
    \nabla_1 \psi_T =& \left(-\alpha\omega\mathbf{r}_1 + \frac{(\mathbf{r}_1 - \mathbf{r}_2)}{r_{12}} \frac{a}{(1+\beta r_{12})^2}\right)C\exp(u)\exp(v)\\
    \nabla_2 \psi_T =& \left(-\alpha\omega\mathbf{r}_2 - \frac{(\mathbf{r}_1 - \mathbf{r}_2)}{r_{12}} \frac{a}{(1+\beta r_{12})^2}\right)C\exp(u)\exp(v).
\end{align}
To find the Laplacian we need 
\begin{align}
    \nabla_1 (-\alpha\omega\mathbf{r}_1) = -\alpha\omega d = -2\alpha\omega,
\end{align}
where $d$ is the number of dimensions, in our case $d=2$. We also need 
\begin{align}
\begin{split}
    \nabla_1 \left(\frac{(\mathbf{r}_1 - \mathbf{r}_2)}{r_{12}} \frac{a}{(1+\beta r_{12})^2}\right) =& \frac{a}{(1+\beta r_{12})^2}\nabla_1 \frac{(\mathbf{r}_1 - \mathbf{r}_2)}{r_{12}} + \frac{(\mathbf{r}_1 - \mathbf{r}_2)}{r_{12}} \nabla_1 \frac{a}{(1+\beta r_{12})^2}\\
    =& \frac{d-1}{r_{12}}\frac{a}{(1+\beta r_{12})^2} + \frac{(\mathbf{r}_1 - \mathbf{r}_2)}{r_{12}}\frac{(\mathbf{r}_1 - \mathbf{r}_2)}{r_{12}}\frac{\partial}{\partial r_{12}} \frac{a}{(1+\beta r_{12})^2}\\
    =& \frac{1}{r_{12}} \frac{a}{(1+\beta r_{12})^2} - \frac{2a\beta}{(1+\beta r_{12})^3}.
\end{split}
\end{align}
We also have 
\begin{align}
    \nabla_2 (-\alpha\omega\mathbf{r}_2) = \nabla_1 (-\alpha\omega\mathbf{r}_1),
\end{align}
and 
\begin{align}
    \nabla_2 \left(-\frac{(\mathbf{r}_1 - \mathbf{r}_2)}{r_{12}} \frac{a}{(1+\beta r_{12})^2}\right) = \nabla_1 \left(\frac{(\mathbf{r}_1 - \mathbf{r}_2)}{r_{12}} \frac{a}{(1+\beta r_{12})^2}\right)
\end{align}
We end up with the Laplacians 
\begin{align}
    \frac{\nabla_1^2\psi_T}{\psi_T} =& \left(-2\alpha\omega + \frac{1}{r_{12}} \frac{a}{(1+\beta r_{12})^2} - \frac{2a\beta}{(1+\beta r_{12})^3} + \left(-\alpha\omega\mathbf{r}_1 + \frac{(\mathbf{r}_1 - \mathbf{r}_2)}{r_{12}} \frac{a}{(1+\beta r_{12})^2}\right)^2\right)\\
    \frac{\nabla_2^2\psi_T}{\psi_T} =& \left(-2\alpha\omega + \frac{1}{r_{12}} \frac{a}{(1+\beta r_{12})^2} - \frac{2a\beta}{(1+\beta r_{12})^3} + \left(-\alpha\omega\mathbf{r}_2 - \frac{(\mathbf{r}_1 - \mathbf{r}_2)}{r_{12}} \frac{a}{(1+\beta r_{12})^2}\right)^2\right).
\end{align}
The sum of the Laplacians in the Hamiltonian is then
\begin{align}
\begin{split}
    \frac{\nabla_1^2\psi_T}{\psi_T} + \frac{\nabla_2^2\psi_T}{\psi_T} = &-4\alpha\omega + \frac{1}{r_{12}}\frac{a}{(1+\beta r_{12})^2} - \frac{2a\beta}{(1 + \beta r_12)^3}\\
    &+ \alpha^2\omega^2(r_1^2 + r_2^2) + \frac{2a^2}{(1+\beta r_{12})^4} - \alpha\omega r_{12}\frac{2a}{(1+\beta r_{12})^2}.
\end{split}
\end{align}
The complete expression for the local energy is then 
\begin{align}
\begin{split}
    E_L =& \frac{1}{\psi_T}H\psi_T\\
    =& 2\alpha\omega + \frac{1}{r_{12}}\frac{a}{(1+\beta r_{12})^2} - \frac{2a\beta}{(1 + \beta r_12)^3} - \frac{1}{2}\alpha^2\omega^2(r_1^2 + r_2^2) \\
    &- \frac{a^2}{(1+\beta r_{12})^4} + \alpha\omega r_{12}\frac{a}{(1+\beta r_{12})^2} + \frac{1}{2}\omega^2(r_1^2 + r_2^2) + \frac{1}{r_{12}}\\
    =& 2\alpha\omega + \frac{1}{2}\omega^2(r_1^2 + r_2^2)(1 - \alpha^2) - \frac{2a\beta}{(1 + \beta r_12)^3} \\
    &- \frac{a^2}{(1+\beta r_{12})^4} + \left(\alpha\omega r_{12} + \frac{1}{r_{12}}\right)\frac{a}{(1+\beta r_{12})^2} + \frac{1}{r_{12}}.
\end{split}
\end{align}

\section{Many-body quantum dots}\label{sec:ClosedFormMany}
These calculations follow Ref.~\cite{FYS4411-LectureNotes}.
In the many-body case we have the trial wave function 
\begin{align}
    \psi_{T}({\bf r_1},{\bf r_2},\dots, {\bf r_N}) = 
   Det\left(\phi_{1}({\bf r_1}),\phi_{2}({\bf r_2}),
   \dots,\phi_{N}({\bf r_N})\right)
   \prod_{i<j}^{N}\exp{\left(\frac{a r_{ij}}{(1+\beta r_{ij})}\right)}, 
\end{align}
where $Det$ is a Slater determinant, and the single-particle wave functions
are the harmonic oscillator wave functions given by
\begin{align}
    \phi_{n_x,n_y}(x,y) = A H_{n_x}(\sqrt{\omega}x)H_{n_y}(\sqrt{\omega}y)\exp{(-\omega(x^2+y^2)/2}.
\end{align}
$A$ is a normalization constant, while the functions $H_{n_x}(\sqrt{\omega}x)$ are Hermite polynomials. For $N=6$ electrons we need the Hermite polynomials for $n_x = 0,1$ and $n_y = 0,1$, for $N=12$ we need to include the $n_x,n_y = 2$ Hermite polynomials, and for $N=20$ we also need the Hermite polynomials for $n_x,n_y = 3$. When evaluating the trial wave function, the calculation of the gradient and the Laplacian of an $N$-particle Slater determinant is likely to be most time-consuming. This is because we have to differentiate with respect to all spatial coordinates of all electrons. We can improve the efficiency of the calculation by moving only one electron at the time. When we then differentiate the Slater determinant with respect to a given coordinate of that electron, only one row in the corresponding Slater matrix is changed. This means that we do not have to recalculate the entire determinant at every Metropolis step. Instead we use an algorithm which requires us to keep track of the inverse of the Slater matrix. 

The matrix elements of the Slater matrix $\hat{D}$ are given by 
\begin{align}
    d_{ij} = \phi_j(x_i),
\end{align}
where $\phi_j({\bf r_i})$ is a single particle wave function. $x_i$ is one of the spatial coordinates of the given particle, while $j$ indicates the quantum numbers ($n_x$ and $n_y$ in our case).
The inverse of $\hat{D}$ can be expressed by its determinant $|\hat{D}|$, and its cofactors $C_{ij}$ as follows
\begin{align}\label{eq: invdet}
    d_{ij}^{-1} = \frac{C_{ji}}{|\hat{D}|}, 
\end{align}
where the interchanged indices of $C_{ji}$ means that the cofactor matrix should be transposed. Assuming $\hat{D}$ is invertible we have
\begin{align}\label{eq: unity}
    \sum_{k=1}^N d_{ik}d_{kj}^{-1} = \delta_{ij}.
\end{align}
We define the ratio $R$, between $|\hat{D}({\bf r}^{\textrm{new}})|$ and $|\hat{D}({\bf r}^{\textrm{old}})|$, which by definition can be expressed as
\begin{align}\label{eq: R1}
    R \equiv \frac{|\hat{D}({\bf r}^{\textrm{new}})|}{|\hat{D}({\bf r}^{\textrm{old}})|} 
    = \frac{\sum_{j=1}^N d_{ij}({\bf r}^{\textrm{new}}) C_{ij}({\bf r}^{\textrm{new}})}{\sum_{j=1}^N d_{ij}({\bf r}^{\textrm{old}}) C_{ij}({\bf r}^{\textrm{old}})}.
\end{align}
If we move only one electron at a time, ${\bf r}^{\textrm{new}}$ and ${\bf r}^{\textrm{old}}$ differ only by the position of that one, $i$-th, electron, which means $\hat{D}({\bf r}^{\textrm{new}})$ and $\hat{D}({\bf r}^{\textrm{old}})$ differ only by the entries of the $i$-th row. The $i$-th row of a cofactor matrix $\hat{C}$ is independent of the entries in the $i$-th row of the corresponding matrix $\hat{D}$. In our case this means that the $i$-th row of $\hat{C}({\bf r}^{\textrm{new}})$ and $\hat{C}({\bf r}^{\textrm{old}})$ must be equal, so we have 
\begin{align}\label{eq: equalC}
    C_{ij}({\bf r}^{\textrm{new}}) = C_{ij}({\bf r}^{\textrm{old}})\quad \forall \ j \in \{1, \dots, N\}.
\end{align}
We use Eq.~(\ref{eq: invdet}) and Eq.~(\ref{eq: equalC}) with Eq.~(\ref{eq: R1}) in order to obtain
\begin{align}
    R = \frac{\sum_{j=1}^N d_{ij}({\bf r}^{\textrm{new}}) C_{ij}({\bf r}^{\textrm{old}})}{\sum_{j=1}^N d_{ij}({\bf r}^{\textrm{old}}) C_{ij}({\bf r}^{\textrm{old}})} 
    = \frac{\sum_{j=1}^N d_{ij}({\bf r}^{\textrm{new}}) d_{ji}^{-1}({\bf r}^{\textrm{old}})}{\sum_{j=1}^N d_{ij}({\bf r}^{\textrm{old}}) d_{ji}^{-1}({\bf r}^{\textrm{old}})},
\end{align}
where, by Eq.~(\ref{eq: unity}), the denominator of the rightmost expression is unity, and we end up with
\begin{align}
    R = \sum_{j=1}^N d_{ij}({\bf r}^{\textrm{new}}) d_{ji}^{-1}({\bf r}^{\textrm{old}}) = \sum_{j=1}^N \phi_j({\bf r}_i^{\textrm{new}}) d_{ji}^{-1}({\bf r}^{\textrm{old}}).
\end{align}
This means that if we only move the $i$-th electron, the ratio $R$ is given by the dot product between the vector, ($\phi_1({\bf r}_i^{\textrm{new}}),\dots,\phi_N({\bf r}_i^{\textrm{new}})$), of single particle wave functions evaluated at the new position, and the $i$-th column of the inverse matrix $\hat{D}^{-1}$ evaluated at the original position.

We need to maintain the inverse matrix, so if the new position ${\bf r}^{\textrm{new}}$ is accepted we need to use an algorithm for updating the inverse matrix. We start by updating all but the $i$-th column of $\hat{D}^{-1}$. For each column $j\neq i$, we calculate 
\begin{align}
    S_j = (\hat{D}({\bf r}^{\textrm{new}})\times \hat{D}^{-1}({\bf r}^{\textrm{old}}))_{ij} = \sum_{l=1}^N d_{il}({\bf r}^{\textrm{new}}) d_{lj}^{-1}({\bf r}^{\textrm{old}}), 
\end{align}
then we calculate the new elements of the $j$-th column of $\hat{D}^{-1}$ as follows
\begin{align}
    d_{kj}^{-1}({\bf r}^{\textrm{new}}) = d_{kj}^{-1}({\bf r}^{\textrm{old}}) - \frac{S_j}{R} d_{ki}^{-1}({\bf r}^{\textrm{old}}) \quad 
    \begin{array}{ll}
    \forall\ \ k\in\{1,\dots,N\}\\j\neq i
    \end{array}.
\end{align}
The last step is to update the $i$-th column of $\hat{D}^{-1}$ using the following equation
\begin{align}
    d_{ki}^{-1}(\mathbf{r}^{\mathrm{new}}) =
\frac{1}{R}\,d_{ki}^{-1}(\mathbf{r}^{\mathrm{old}})\quad
\forall\ \ k\in\{1,\dots,N\}.
\end{align}
Only the $i$-th row of the Slater matrix changes when differentiating the Slater determinant with respect to the coordinates of a single particle ${\bf r}_i$ as well, which means we can calculate the gradient and the Laplacian as follows 
\begin{align}\label{eq: gradSlater}
    \frac{\vec\nabla_i\vert\hat{D}(\mathbf{r})\vert}{\vert\hat{D}(\mathbf{r})\vert} =
    \sum_{j=1}^N \vec\nabla_i d_{ij}(\mathbf{r})d_{ji}^{-1}(\mathbf{r}) =
    \sum_{j=1}^N \vec\nabla_i \phi_j(\mathbf{r}_i)d_{ji}^{-1}(\mathbf{r})
\end{align}
and
\begin{align}\label{eq: lapSlater}
    \frac{\nabla^2_i\vert\hat{D}(\mathbf{r})\vert}{\vert\hat{D}(\mathbf{r})\vert} =
    \sum_{j=1}^N \nabla^2_i d_{ij}(\mathbf{r})d_{ji}^{-1}(\mathbf{r}) =
    \sum_{j=1}^N \nabla^2_i \phi_j(\mathbf{r}_i)\,d_{ji}^{-1}(\mathbf{r}).
\end{align}
Therefore in order to calculate the derivatives of the Slater determinant, we only need the derivatives of the single particle wave functions and the elements of the inverse Slater matrix.

The expectation value of the kinetic energy for electron $i$ expressed in atomic units is 
\begin{align}
    \langle \hat{K}_i \rangle = -\frac{1}{2}\frac{\langle\Psi|\nabla_{i}^2|\Psi \rangle}{\langle\Psi|\Psi \rangle}, 
\end{align}
and we have that 
\begin{align}
    K_i = -\frac{1}{2}\frac{\nabla_{i}^{2} \Psi}{\Psi}.
\end{align}
To find the kinetic energy we need the Laplacian of the wave function. We define the Slater determinant part of the wave function as $\Psi_D$ and define the correlation part (Jastrow factor) as $\Psi_C$. The Laplacian is then 
\begin{align}\label{eq: TotalLaplacian}
\begin{split}
    \frac{\nabla^2 \Psi}{\Psi} & =  \frac{\nabla^2 ({\Psi_{D} \,  \Psi_C})}{\Psi_{D} \,  \Psi_C} = \frac{\nabla  \cdot [\nabla  {(\Psi_{D} \,  \Psi_C)}]}{\Psi_{D} \,  \Psi_C} = \frac{\nabla  \cdot [ \Psi_C \nabla  \Psi_{D} + \Psi_{D} \nabla   \Psi_C]}{\Psi_{D} \,  \Psi_C}\\
    &  =  \frac{\nabla   \Psi_C \cdot \nabla  \Psi_{D} +  \Psi_C \nabla^2 \Psi_{D} + \nabla  \Psi_{D} \cdot \nabla   \Psi_C + \Psi_{D} \nabla^2  \Psi_C}{\Psi_{D} \,  \Psi_C}\\
    & =  \frac{\nabla^2 \Psi_{D}}{\Psi_{D}} + \frac{\nabla^2  \Psi_C}{ \Psi_C} + 2 \frac{\nabla  \Psi_{D}}{\Psi_{D}}\cdot\frac{\nabla   \Psi_C}{ \Psi_C}.
\end{split}
\end{align}
From Eq.~(\ref{eq: TotalLaplacian}) we see that we need the gradient and Laplacian of both $\Psi_D$ and $\Psi_C$. For $\Psi_D$ the necessary expression are given by Eq.~(\ref{eq: gradSlater}) and Eq.~(\ref{eq: lapSlater}). We have that 
\begin{align}
    \Psi_{C}=\prod_{i< j}\exp{f(r_{ij})}= \exp{\left\{\sum_{i<j}\frac{ar_{ij}}{1+\beta r_{ij}}\right\}},
\end{align}
and by differentiating with the chain rule similarly to what we did in Eq.~(\ref{eq: chainDeriv}), we find that the gradient is 
\begin{align}
    \frac{ \nabla_k \Psi_C}{ \Psi_C }= \sum_{j\ne k}\frac{{\bf r}_{kj}}{r_{kj}} \frac{\partial f(r_{kj})}{\partial r_{kj}} = \sum_{j\ne k}\frac{{\bf r}_{kj}}{r_{kj}} f'(r_{kj}) = \sum_{j\ne k}\frac{{\bf r}_{kj}}{r_{kj}}\frac{a}{(1+\beta r_{kj})^2},
\end{align}
where 
\begin{align}
    f'(r_{kj}) = \frac{\partial}{\partial r_{kj}} f(r_{kj}).
\end{align}
To find the Laplacian we need to calculate
\begin{align}
    \frac{\nabla^2_k \Psi_C}{\Psi_C } = \frac{1}{ \Psi_C }\nabla_k\sum_{j\ne k}\frac{{\bf r}_{kj}}{r_{kj}} f'(r_{kj}) \Psi_C.
\end{align}
We follow the calculations from Ref.~\cite{FYS4411-LectureNotes}. Using the product rule we get
\begin{align}
    \frac{\nabla^2_k \Psi_C}{\Psi_C } = &\frac{1}{ \Psi_C }\sum_{j\ne k}\left(\frac{{\bf r}_{kj}}{r_{kj}} f'(r_{kj}) \nabla_k\Psi_C + \frac{{\bf r}_{kj}}{r_{kj}} \Psi_C \nabla_k f'(r_{kj}) + f'(r_{kj}) \Psi_C \nabla_k\frac{{\bf r}_{kj}}{r_{kj}}\right)\\
    = &\sum_{ij\ne k}\frac{({\bf r}_k-{\bf r}_i)({\bf r}_k-{\bf r}_j)}{r_{ki}r_{kj}}f'(r_{ki})f'(r_{kj})+
    \sum_{j\ne k}\left( f''(r_{kj})+\frac{d-1}{r_{kj}}f'(r_{kj})\right),
\end{align}
where $d$ is the number of dimensions. We end up with the following expression 
\begin{align}
    \frac{\nabla^2_k \Psi_C}{\Psi_C }=
    \sum_{ij\ne k}\frac{({\bf r}_k-{\bf r}_i)({\bf r}_k-{\bf r}_j)}{r_{ki}r_{kj}}\frac{a}{(1+\beta r_{ki})^2}
    \frac{a}{(1+\beta r_{kj})^2}+
    \sum_{j\ne k}\left(\frac{a}{r_{kj}(1+\beta r_{kj})^2}-\frac{2a\beta}{(1+\beta r_{kj})^3}\right).
\end{align}


\chapter{Program Structure}\label{sec: Program Structure Appendix}

The simulations in this thesis were done by two programs implemented in C++ using object-orientation. 
The variational Monte Carlo (VMC) simulation program consists of several classes responsible for different parts of the simulations. The following classes are responsible for the VMC simulations in this thesis. Any other classes from the vmc-solver folder in the Github repository \cite{github} are outside the scope of this thesis.
\begin{itemize}
    \item {\bf Hamiltonian:} A super-class for different Hamiltonians. The subclasses calculate the local energy for their specific Hamiltonian. They also calculate the single particle wave functions if these are not approximated by expanding in a basis of single harmonic oscillator functions (not implemented for the square well). Since calculating the kinetic energy with numerical differentiation is done the same for all Hamiltonians, this super-class is responsible for that. The subclasses are:
    \begin{itemize}
        \item \textbf{HarmonicOscillatorElectrons:} Calculates the local energy for quantum dots in a single harmonic oscillator potential well.
        \item \textbf{DoubleHarmonicOscillator:} Calculates the local energy for quantum dots in a double harmonic oscillator potential well.
        \item \textbf{SquareWell:} Calculates the local energy for quantum dots in a finite square well potential.
    \end{itemize}
    \item \textbf{HermitePolynomials:} Stores the expressions for Hermite polynomials and their derivatives and double derivatives in individual subclasses. All subclasses are included in the superclass file. The first $50$ Hermite polynomials are implemented, which means a total of $150$ subclasses ($50$ each for polynomial, derivative and double derivate).
    \item {\bf WaveFunction:} A super-class for different wave functions. The subclasses evaluate their specific wave function and also calculate the gradient, the Laplacian and the derivative w.r.t. the variational parameters $\alpha$ and $\beta$. The subclasses are:
    \begin{itemize}
        \item \textbf{ManyElectrons:} WaveFunction subclass for many-body quantum dots This includes all Slater determinant functionality. This class uses single/double harmonic oscillator single particle wave functions directly, which it gets from the corresponding Hamiltonian subclasses.
        \item \textbf{ManyElectrons\_Coefficients:} Similar to ManyElectrons, but with the one key difference that it approximates the single particle wave functions by expansion in a single harmonic oscillator basis.
    \end{itemize}
    \item {\bf InitialState:} A super-class for different initial states. The subclasses set up the initial state. The subclasses are:
    \begin{itemize}
        \item {\bf RandomUniform:} Sets up an initial state with uniformly distributed particle positions. The particles are distributed around the well center (or centers in the double well case).
    \end{itemize}
    \item {\bf Particle:} Responsible for creating particles and adjusting their positions.
    \item {\bf System:} Responsible for running the Monte Carlo simulation. It performs the Metropolis and Metropolis-Hastings algorithms.
    \item {\bf Sampler:} Responsible for sampling interesting quantities and computing averages. It is also responsible for providing the data to the user, both by printing to terminal and saving to file.
    \item {\bf SteepestDescent:} Responsible for optimizing variational parameters using the Steepest Descent method. Once the optimal parameter has been found, the System class is tasked with running a large Monte Carlo simulation.
    \item {\bf Random:} Responsible for generating pseudo-random numbers according to different distributions.
\end{itemize}

There is also a main program which sets the necessary parameters and makes calls to the classes to start the simulation. The code is also fully parallelized with MPI. An advantage to using an implementation like this is that it makes it easy to add functionality, like other potentials and alternative methods for optimizing variational parameters (e.g. the Conjugate Gradient method). 

The other program used is the diagonalization program, which is responsible for diagonalizing the single particle problem for a given potential, and then find the overlap with the single harmonic oscillator basis. The overlap coefficients are then saved to a file so they can be used by the VMC solver. This program consists of:
\begin{itemize}
    \item \textbf{WaveFunction:} This superclass contains subclasses for different potentials. The subclasses also calculate the harmonic oscillator basis functions. The "WaveFunction" superclass also computes the Hermite polynomials used in the basis functions. If other types of basis functions are implemented, a new basis functions superclass should be made, and the harmonic oscillator basis functions should be calculated by a subclass of that basis functions superclass. 
    \begin{itemize}
        \item \textbf{DoubleWell:} Subclass for the double harmonic oscillator potential. This subclass is also used for the single harmonic oscillator potential by setting the $L$ parameter for each dimension to $0$.
        \item \textbf{SquareWell:} Subclass for the square well potential. In this thesis only single square wells were simulated, no double (or multi) square wells.
    \end{itemize}
    \item \textbf{System:} This class is responsible for doing the diagonalization, and finding the overlap coefficients. It also has functionality for approximating the single particle wave functions by expansion in a single harmonic oscillator basis. This functionality was only added for testing purposes, as the VMC solver needs to do this itself mid-simulation (for varying particle positions).
\end{itemize}

Here as well, there is a main program which sets the necessary parameters, and gets the "System" class started. It also saves necessary data to files (e.g. the overlap coefficients). The data analysis is done in Python, with the programs {\bf blocking.py} and {\bf density.py}. Testing of the diagonalization program was done by the Python program \textbf{plot\_data.py}, and plots of the potentials were created using \textbf{potential.py}. Finally, the code for the Hermite polynomial subclasses in the VMC solver was generated automatically with SymPy in the program \textbf{hermitePolynomialGenerator.py}. For the C++ programs the library Armadillo\cite{Armadillo} was used extensively for matrix operations etc. Open MPI\cite{Open MPI} was used for parallel computing. For the Python programs the following packages were used: Matplotlib\cite{Matplotlib}, NumPy\cite{NumPy}, and SymPy\cite{SymPy}.



\chapter{Code Generation with SymPy}

In order to optimize the variational Monte Carlo (VMC) solver, we wanted to have explicit expressions for a lot of Hermite polynomials and corresponding derivatives and double derivatives. Not only would it be an extensive amount of work to calculate the expressions by hand, but writing the code to implement the expressions would also be a lot of work. In addition the risk of committing error during the implementation would be great. Instead we can use SymPy\cite{SymPy} for this task, which is a Python library for symbolic mathematics. This means that we can for example do symbolic differentiation with a Python program. This is extremely useful in our case since we need to symbolically differentiate a lot of expressions. We also use SymPy to symbolically calculating new Hermite polynomials using the recursive relation of Hermite polynomials. First we specify what variables SymPy should treat as symbols with the "symbols" function:
\lstset{language=python}
\begin{lstlisting}[caption={}]
x, a, w, aw = symbols('x, m_alpha, m_omega, m_alphaomega')
\end{lstlisting}
Now we can simply set up the recursion relation of the Hermite polynomials, with these symbols in place of $x$, $\alpha$ and $\omega$ values:
\lstset{language=python}
\begin{lstlisting}[caption={}]
H[0] = 1

for n in range(1, nMax):
	H[n] = simplify(2*sqrt(aw)*x*H[n-1] - diff(H[n-1], x))
\end{lstlisting}
The "simplify" function ensures the result is on a simple form (or at least as simple as possible). The "diff" function does a symbolic differentiation on the first argument with respect to the second argument. Now we have all the Hermite polynomials we need on symbolic form. We continue by finding the derivatives with the following simple loop:
\lstset{language=python}
\begin{lstlisting}[caption={}]
for n in range(0, nMax):
	Hd[n] = simplify(diff(H[n], x))
\end{lstlisting}
and the double derivatives with:
\lstset{language=python}
\begin{lstlisting}[caption={}]
for n in range(0, nMax):
	Hdd[n] = simplify(diff(H[n], x, 2))
\end{lstlisting}
where the third argument of "diff" indicates that we want to differentiate twice. Now we have all the symbolic expressions we need, but with one more simple function we can get more out of SymPy. The function "codegen" can automatically create C functions for calculating our Hermite expressions, and print these expression to the terminal so we can copy them into our C++ code. With the simple code:
\lstset{language=python}
\begin{lstlisting}[caption={}]
for n in range(0, nMax):
	print codegen(("HermitePolynomial_%i::eval" %n, H[n]), "c", "file", header=False)[0][1]
	print codegen(("dell_HermitePolynomial_%i::eval" %n, Hd[n]), "c", "file", header=False)[0][1]
	print codegen(("lapl_HermitePolynomial_%i::eval" %n, Hdd[n]), "c", "file", header=False)[0][1]
\end{lstlisting}
we get terminal output on the following form:
\begin{lstlisting}[caption={}, style=Bash]
#include "file.h"
#include <math.h>

double HermitePolynomial_0::eval() {

   double HermitePolynomial_0::eval_result;
   HermitePolynomial_0::eval_result = 1;
   return HermitePolynomial_0::eval_result;

}

#include "file.h"
#include <math.h>

double dell_HermitePolynomial_0::eval() {

   double dell_HermitePolynomial_0::eval_result;
   dell_HermitePolynomial_0::eval_result = 0;
   return dell_HermitePolynomial_0::eval_result;

}

#include "file.h"
#include <math.h>

double lapl_HermitePolynomial_0::eval() {

   double lapl_HermitePolynomial_0::eval_result;
   lapl_HermitePolynomial_0::eval_result = 0;
   return lapl_HermitePolynomial_0::eval_result;

}

\end{lstlisting}
This output still needs some modifications before it can be used in the VMC solver. SymPy has a lot more advanced functionality which could get us the exact output we want, but since the generated code we need is fairly general the modifications can be easily done with the find/replace option of a text editor. The first thing we do is replace all the "\#include" lines with nothing, since we copy all the functions into the same file which we have set up beforehand. Next we replace the name of the variable in each function with something simple. To do this we replace the phrase "ermitePolynomial\_0::eval\_result" with nothing and do this again with the $0$ changed to the numbers needed. In our case this involves $50$ find/replace commands, but since the only thing we need to change in between is one number, it is quickly done. Our variables then end up as simply "H", "dell\_H" and "lapl\_H".

The modifications done so far are not strictly necessary, but was done to clean up the code somewhat. The next two modifications are needed for the VMC simulation to work properly. First we need to add an argument to the functions, since we want to send in the position $x$. This is done by replacing "eval()" with "eval(double x)". The final modification is needed due to an issue we run into with the int type in C++ when we have larger Hermite polynomials. For Hermite polynomial number $50$, the expressions involve large integers, e.g. $12699589412983995191626304930774935142400000$. Since SymPy simply prints the numbers like this, they are considered as int type when copied into the C++ program. However, the number is too large to be an int type in C++, so we need to change the type. This is done by simply adding a period to the end of the these numbers. These large numbers are always a constant in front of a pow function in our auto-generated code, so the code looks like "i*pow(", where "i" is the integer. We can then simply replace "0*pow(" with "0.*pow", and do this for $0,\dots,9$ so that the change is done to all relevant integers regardless of what the last digit is.

An alternative to using "codegen", is to use the SymPy function "printing.ccode" to print the Hermite expressions as C code instead of Python code (e.g. changing "1**2" to "pow(1, 2)"). We can then create our own custom string to print out with the variable names we want, no "include" lines,  etc. This makes the code in "hermitePolynomialGenerator.py" somewhat messy, but in return the only modification we need to make after generating the code is to add the periiods discussed above. Instead of the "codegen" code, we would then use the following:
\lstset{language=python}
\begin{lstlisting}[caption={}]
for n in range(0, nMax):
	print("""double HermitePolynomial_%i::eval(double x) {

   double H;
   H = %s;
   return H;

}




double dell_HermitePolynomial_%i::eval(double x) {

   double dell_H;
   dell_H = %s;
   return dell_H;

}




double lapl_HermitePolynomial_%i::eval(double x) {

   double lapl_H;
   lapl_H = %s;
   return lapl_H;

}""" %(n, printing.ccode(H[n]), n, printing.ccode(Hd[n]), n, printing.ccode(Hdd[n])))
\end{lstlisting}
We also use this approach to auto-generate the class constructors and declarations, as well as the code to store the "HermitePolynomials" objects in arrays.

\end{appendices}

\end{document}