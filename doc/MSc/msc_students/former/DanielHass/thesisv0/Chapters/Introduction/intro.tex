\chapter{Introduction}
\section{The Quantum Many-body Problem}

Quantum mechanics stands as one of the most significant scientific achievements of the twentieth century, impacting both technological developments and our understanding of reality through its precise theoretical formalism. Despite substantial progress since the early 1920s, applying quantum mechanics to practical problems remains challenging, particularly for quantum many-body systems. These systems are central to various fields of physics, including condensed matter physics, quantum chemistry, atomic, molecular, and nuclear physics.

The core concepts of non-relativistic quantum mechanics are well condensed in the Schrödinger equation. However, the theoretical framework is only part of the challenge, and modelling even medium-sized interactive systems is a task of significant computational difficulty. This is because the dimension of a quantum system, or the Hilbert space, scales exponentially, making an exact solution of the Schrödinger equation for many-body systems unattainable. Though some classical systems also lack analytical solutions, this analysis focuses on the scaling of dimensionality, which is significantly more challenging in quantum systems.

With the advent of computers, the focus shifted towards solving the Schrödinger equation computationally and developing approximation methods to tackle larger systems. A brief description of some of the classical methods for approximating solutions follows: the Hartree-Fock (HF) method \cite{szabo2012modern}, which provides a reasonably efficient first approximation, neglects higher-order electron correlations by considering only a mean-field picture. Full Configuration Interaction (FCI) \cite{szabo2012modern} offers exact solutions within a given basis set but is computationally infeasible for large systems due to exponential scaling. Truncated Configuration Interaction (CI) methods \cite{Shavitt_Bartlett_2009} account for only some set of excitations, balancing accuracy and computational feasibility.

There are additional methods to include, but despite their effectiveness, they all face limitations in either accuracy or scalability. Configuration Interaction methods, for example, are currently restricted to around 20 particles \cite{vogiatzis2017pushing}. Both the memory required to store the Hamiltonian matrix and the computational cost of diagonalisation scale in such a manner that exceeds the capabilities of current computational resources.

In a simplistic way, solving the many-body problem means either learning to represent the high-dimensional quantum states in a more efficient way and/or learning to sample observables from them. One prominent method for specifically doing the latter is quantum Monte Carlo, which is a conceptual cornerstone of our work. Under this label, we mention variational Monte Carlo (VMC) and diffusion Monte Carlo (DMC) \cite{sorellabook}. The former optimises a parameterised guess for the wavefunction, using the variational principle to minimise the energy and obtain the ground-state. If that state is obtained, other observables can be similarly sampled. Variational Monte Carlo provides a flexible approach to incorporate complicated wavefunctions, and while it has the potential to be unbiased, its accuracy depends on the chosen ansatz. Diffusion Monte Carlo improves upon VMC, offering higher accuracy at the cost of greater computational complexity and a more heavy bias from a necessary fixed-node approximation. Therefore, it is crucial to carefully select the functional form and the number of parameters. Even if the correct representation is found, the computational cost of optimising the ansatz increases with the number of parameters. The challenge lies in how to effectively represent quantum states using parameterised functions, and machine learning offers one approach to this problem.

\section{The Many-body Problem as a Machine Learning Task}

The field of machine learning (ML), since its early days, has similarly suffered with dimensionality-exploding problems, in what is referred to as curse of dimensionality. This is because high-dimensional data are incredibly sparse, so the amount of data required for a model to make accurate predictions to unseen data grows exponentially. 

Tensor networks (TN), conceptualised in 1971, were used in quantum many-body problems in the 1990s \cite{white1992density} as perhaps the first crossover between machine learning and many-body physics. Although not developed for machine learning purposes, the connections between TN and ML are now better understood. The idea was to use area-law entanglement to build a network-like ansatz with a polynomial number of parameters. TNs further allowed for symmetries on the wavefunction to be enforced, but these methods did not generalise well beyond one-dimensional systems.

In 2017, Carleo and Troyer \cite{carleo2017solving} proposed a new type of parametrised ansatz based on a restricted Boltzmann machine, a stochastic generative neural network specifically aimed at unsupervised learning. Their approach was coined the term neural quantum states (NQS), and its success led to an investigation between tensor networks and the newly defined neural quantum states. We now know that neural quantum states display the same or higher expressive power than practical tensor networks, while being more efficient \cite{sharir2022neural}. This is because RBMs have been shown to obey volume-law scaling, which allows them to represent quantum many-body states irrespective of their level of entanglement \cite{deng2017quantum}.

RBMs are universal approximators \cite{le2008representational}, which led researchers to question if other universal approximators could equally represent quantum states with a small number of parameters. Various neural network architectures, such as convolutional neural networks, feed-forward neural networks, and graph neural networks, among others, have been shown to answer this positively \cite{lange2024architectures}. Certain NQS architectures have shown the capability to surpass classical techniques such as coupled clustering for specific systems \cite{ferminet}, while other approaches outperform state-of-the-art DMC calculations \cite{kim2023neuralnetwork}. Neural networks have also been used to accurately model excited states \cite{pfau2023natural}, and even more recently to approximate the time evolution of
quantum systems with great results \cite{lawrence2024quantum}. This evidence further points to neural networks as a promising path to solve the quantum many-body problem.

This thesis aims to explore this recent intersection between quantum many-body problems and machine learning. To do so, we compare how three methods perform in two bound fermionic systems: a one-dimensional fully polarised fermion system and a two-dimensional quantum dots system. The models tested were a standard VMC parameterisation, an RBM implementation, and a specific variant of a feed-forward network. We further explored the use of Slater-Jastrow variants for the ansätze to impose fermionic antisymmetry and correlations. The implementation was carried out using Python with JAX, inspired by their recent efficient use in quantum many-body problems \cite{vicentini2022netket, jane}.

\section{Overview and Thesis Structure}

Trying to address the presented many-body problem bears resemblance to some of the methods that we are going to address in this thesis. It is like an optimisation problem, where we try to minimise how wrong we are in our description of nature. Here, we have a space of theories or approaches, which is clearly infinite and which we test on a reference frame of arbitrary physical systems. This exploration process is non-convex, and moving in one direction brings advantages, accompanied by some disadvantages.

This thesis is not unique in its topics. Previous works have approached the same systems and have used similar methods. However, I tried to make this work personal in its didactic aspect. This means that theory is presented in a way that feels natural to me and connects points that I consider fundamental. I have tried to include here the answer to every theoretical question I asked myself along the way, with the amount of detail and rigour that at the time was sufficient to understand concepts and, eventually, move on. If a certain approach seems too big of a detour, I was probably connecting dots that for me are enlightening. If it seems too trivial, I was probably covering a gap in my knowledge. With this comes an inevitable loss in linearity of narrative, and that I tried to make evident when possible. On that note, the structure of the thesis is presented below. 

In the theory part, Chapter \ref{ch:qm_background}, provides a review of basic quantum mechanics, followed by a discussion of quantum many-body physics, and a description of the systems examined in this study. Chapter \ref{ch:computational} focusses on the computational background, from the theory of Markov chains, its connections with variational Monte Carlo, and diffusion Monte Carlo. Last in the theory section, Chapter \ref{chap:ml} starts with a theoretical treatment of statistical learning and optimisation methods. We proceed by detailing the neural networks used and finish by connecting VMC with reinforcement learning and neural quantum states.

With regard to methodology, Chapter \ref{chap:methods} provides an in-depth look at our implementations. We explain our codebase and the rationale behind certain decisions, with a minimal theoretical treatment. Further, we show how different components are integrated and how investigations were conducted.

The results are presented in Chapters \ref{ch:fermion_1d} and \ref{ch:dots}, along with discussions and a critical evaluation. Lastly, in Chapter \ref{sec:conclusion}, we assess whether the study goals were achieved and summarise the conclusions with the possibility of improvements and future research directions.









