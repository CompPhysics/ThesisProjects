In this chapter, we have introduced machine learning and investigated different supervised learning methods. However, as they are commonly formatted, these algorithms will only make a good extrapolator for some-body data sets. RNNs, built for extrapolations, require too much training data to be helpful in a many-body application (where generating data points is computationally expensive), and the hyperparameter tuning process associated with RNNs is a significant drawback. However, the other machine learning algorithms we investigated here need to be built for extrapolation and thus perform poorly. Thus in the next chapter, we will create a method of formatting a data set, called sequential regression extrapolation (SRE), that will take a simple regression algorithm, such as ridge regression, and turn it into a powerful extrapolator. 