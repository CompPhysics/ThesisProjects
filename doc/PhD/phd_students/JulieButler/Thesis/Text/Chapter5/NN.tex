Neural networks are computational systems that can learn to perform tasks by considering examples, generally without being programmed with any task-specific rules. Another way to phrase this is that a neural network is a computational system that learns to match a given input to the correct output. They are a broad category of machine learning algorithms, including popular algorithms such as convolutional neural networks, recurrent neural networks, and deep learning.

\subsection*{Fully Connected Feedforward Neural Network}

	Though there are many types of neural networks, using just the phrase "neural network" typically refers to a type of neural network known as a fully connected feedforward neural network (FFNN). This type of network can also be known as a multilayer perceptron (MLP) if it has at least one hidden layer. These FFNNs contain many interconnected layers which transform the given input into an output \cite{Ref6}. The base unit of an FFNN is called a neuron, and these neurons are arranged into columns which are called layers \cite{Ref6}. Information in an FFNN moves only forward.
Additionally, each neuron is connected to every neuron in the next layer, and there are no connections between neurons in the same layer. This means that the input to a layer in the neural network is simply the output from the previous layer. As we will see in a moment, each neuron receives a weighted sum of the outputs of all neurons in the previous layer.

		\subsubsection{Mathematics of Neurons and Layers}

		Each neuron is a mathematical function involving a column from a weight matrix, a scalar from a bias vector, and an activation function. We can represent the mathematical form of the ith neuron in the first hidden layer as:

		\begin{equation} \label{neuron}
			\hat{y}_i = f(\sum_{j=1}^M w_{ij}x_j + b_i),
		\end{equation}


		where x is the input to the neural network, w is the weight matrix that scales the input of the neuron, \textbf{b} is the bias vector that ensures the neuron output is non-zero. Finally, the function f is known as the activation function, which adds nonlinearity to the neuron \cite{Ref6}. The weights and biases are free parameters (meaning they are set for the neural network during training), but the activation function is a hyperparameter \cite{Ref6}.

		For each neuron, i, in the first hidden layer of a neural network, we can represent its mathematical form as:

		\begin{equation}\label{first_hidden_layer}
			\hat{y}_i^1 = f^1(\sum_{j=1}^M w_{ij}^1x_j + b_i^1).
		\end{equation}

		We can also write out the mathematical form for the entire first hidden layer as:

		\begin{equation}\label{first_hidden_layer_mv}
			\hat{y}_1 = f^1(W_1\textbf{x} + \textbf{b}_1).
		\end{equation}

		Similarly, for the second hidden layer, we can represent the mathematical form of each neuron as:

		\begin{equation}\label{second_hidden_layer}
			y_i^2 = f^2(\sum_{j=1}^N w_{ij}^2y_j^1 + b_i^2).
		\end{equation}

		Note here that the weights matrix is no longer multiplied by the inputs to the neural network (x) but rather by the output of the first hidden layer. This is because the input to the first hidden layer is the input to the neural network, but the input to the second hidden layer is the output of the first hidden layer. Therefore, we can expand the above equation to be more precise:

		\begin{equation}\label{second_hidden_layer_expanded}
			y_i^2 = f^2(\sum_{j=1}^N w_{ij}^2f^1(\sum_{k=1}^M w_{kj}^1x_k + b_j^1) + b_i^2).
		\end{equation}

		We can also write a mathematical form for the entire second hidden layer in matrix-vector form as:

		\begin{equation}\label{second_hidden_layer_mv}
			\hat{y}_2 = f^2(W_2\hat{y}_1 + \textbf{b}_2),
		\end{equation}

		or more explicitly as

		\begin{equation}\label{second_hidden_layer_mv_expanded}
			\hat{y}_2 = f^2(W_2f^1(W_1\textbf(x) + \textbf{b}_1) + \textbf{b}_2).
		\end{equation}

		Finally, we can use the pattern we have developed to write down the equation for the mathematical output for a neuron on the l-th hidden layer of the neural network. For the i-th neuron on the l-th layer, we can describe it mathematically as:

		\begin{equation}\label{n_th_hidden_layer}
			y_i^l = f^l(\sum_{j=1}^{N_l} w_{ij}^ly_j^{l-1} + b_i^l),
		\end{equation}

		and more explicitly as

		\begin{equation}\label{n_th_hidden_layer_expanded_1}
			y_i^l = f^l(\sum_{j=1}^{N_l} w_{ij}^lf^{l-1}(\sum_{k=1}^{N_{l-1}} w_{kj}^{l-2}y_k^{l-1} + b_j^{l-1}) + b_i^l),
		\end{equation}

		and finally, all the way expanded as

		\begin{equation}\label{n_th_hidden_layer_expanded_2}
			y_i^l = f^l(\sum_{j=1}^{N_l} w_{ij}^l f^{l-1}(\sum_{k=1}^{N_{l-1}} w_{jk}^{l-1}( \cdot \cdot \cdot f^1(\sum_{n=1}^M w_{mn}^1x_n + b_m^1) \cdot \cdot \cdot ) + b_k^{l-1}) + b_j^l).
		\end{equation}

		We can also write a mathematical expression for the output of the entire l-th layer using matrix-vector format as:

		\begin{equation}\label{n_th_hidden_layer_mv}
			\hat{y}_l = f^l (W_l \hat{y}_{l-1} + \textbf{b}_l),
		\end{equation}

		which can be expanded to

		\begin{equation}\label{n_th_hidden_layer_mv_expanded_1}
			\hat{y}_l = f^l(W_lf^{l-1}(W_{l-1}\hat{y}_{l-2} + \textbf{b}_{l-1}) + \textbf{b}_l),
		\end{equation}

		and finally to

		\begin{equation}\label{n_th_hidden_layer_mv_expanded_2}
			\hat{y}_l = f^l(W_lf^{l-1}(W_{l-1}(\cdot \cdot \cdot f^1(W_1\textbf{x} + \textbf{b}_1) \cdot \cdot \cdot) + \textbf{b}_{l-1}) + \textbf{b}_l).
		\end{equation}

		It is a complicated expression and can grow to be very large, but it is a set equation that describes the output of a neural network with l-1 hidden layers and an output layer. So it is also possible to rephrase the definition of a neural network to be an analytical function that maps a set of inputs to a set of outputs using a set of optimized parameters \cite{Ref6}.

	\subsection*{Activation Functions}
	The activation function is nonlinear. Its purpose is to allow the neural network to capture nonlinear patterns in the data set \cite{Ref6}. Without an activation function, a neural network could only produce an output that was a linear combination of the inputs. There are many choices for the activation function for the neurons, but standard activation functions are the sigmoid, the hyperbolic tangent function (tanh), and the rectified linear unit (ReLu) \cite{Ref6}. Some neural network architectures will have some layers with no activation function. For example, it is common to have no activation function on the output layer so as not to constrain the range of values the output layer can produce.

	\subsection*{Loss Functions and Training Neural Networks}

	%%	## Neural Network Loss Function

		A loss function determines how much the output from a neural network differs from the real/expected result. There is no set loss function used with neural networks, but two common loss functions are the mean-squared error loss function and the mean absolute error function. The mean-squared error loss function (MSE) can be defined as:

		$$J_{MSE}(W) = \frac{1}{N}\sum_{i=1}^N (y_i - \hat{y}_i)^2,$$

		where y is the true data set, $\hat{y}$ is the neural network prediction, N is the number of data points in the set, and W is the neural network's weights. The loss function depends on the weights of the neural network because changing the weights of the neural network changes its output.  

		The mean-absolute error loss function (MAE) has a similar form:

		$$J_{MAE}(W) = \frac{1}{N}\sum_{i=1}^N |y_i - \hat{y}_i|..$$

		%%## Finding The Optimized Weights and Biases

		A significant part of working with neural networks is a process known as training, where the weights of the neural network are optimized such that the cost function is minimized. This training process has two phases: the forward pass and the backpropagation.

		%%## Forward Pass

		The forward pass occurs when data is sent through the neural network (left to right on the above graph) to produce a predicted output. This predicted output is fed into the loss function with the actual data set to generate the loss value.

		%%## Backpropagation

		After the forward pass comes backpropagation, where the error from the loss function is backpropagated through the layers of the neural networks, and its weights are adjusted layer by layer so that the next forward pass will result in a reduced loss value. A simple way to optimize the weights of a neural network during backpropagation is through an optimization technique known as gradient descent. The weights of the neural network are adjusted by the derivative of the loss function with respect to the weights, scaled by a hyperparameter known as the learning rate:

		$$W = W - r_{l}\frac{\partial J(W}{\partial W}.$$

		The learning rate (r$_l$) is a number typically much less than one, and it is also a hyperparameter, so its value must be set before the neural network is run.

		The process of training a neural network involves many different iterations of forward pass followed by backpropagation. Typically a training process will continue until a certain number of training iterations has been reached, or the difference in the current loss value compared to the value from the previous iteration is below a certain threshold. However, neural networks should not be trained for an overly long time because this will lead to something called overfitting, where the neural network learns to match the data set it is trained with very well (so it will show a small loss value) but loses all generality when given new data (so it will perform poorly when given the new data set).
	

%% ADD MORE HEREE
\subsection*{Recurrent Neural Networks}
	There are many different types of neural networks besides the basic FFNN, such as convolutional neural networks (CNNs) and recurrent neural networks (RNNs) \cite{Ref6}. However, RNNs will be the focus of this section as they are designed to handed ordered data, which may make them better at extrapolations than regular neural networks. Furthermore, recurrent neural networks can be used to analyze time series data; thus, they have typical applications in finance.  

    In feedforward neural networks, data only flows in one direction, from an input layer to the output layer. The architecture of a recurrent neural network will look very similar to a feedforward neural network, except each neuron feeds its output back into itself and sends its output to the next layer. For every data point the RNN receives, each neuron receives both the input from the previous layer (using the same equations as a feedforward neural network) and its output from the previous data point. This combination of inputs gives an RNN a memory, making it capable of predicting the future when analyzing time series data or being an extrapolator for other data sets.

    The main problem RNNS faces is a vanishing or exploding gradient that can occur during the training process. It is possible to fix this problem using different types of RNN layers. Common alternative RNN layers are long-short-term memory layers (LSTM) and gated rectified unit layers (GRU).


%% ADD MORE HERE
\subsection*{A Discussion on Neural Network Hyperparameters}
	One of the drawbacks of neural networks is that they have many hyperparameters that need to be set by the user before the neural network can be trained. Examples of hyperparameters include the activation function, the learning rate, the use of dropout during the training process, etc. When using RNNs, the type of RNN layer (regular, LSTM, or GRU) adds another set of hyperparameters. Additionally, the number of layers in the neural network defines its depth, and the number of neurons in the hidden layers defines the width of the neural network \cite{Ref6}. Both of these are also hyperparameters. A network's ability to find patterns in complex data is governed by the number of hidden layers and neurons the network contains, but too many neurons and layers can make for a slow training process \cite{Ref6}. Thus, with the vast number of possible hyperparameter combinations present in neural networks, hyperparameter tuning can be difficult and time-consuming.
Additionally, since neural network weights are initialized randomly, and the optimization of the weights is typically not performed with a closed-form optimization algorithm, a neural network will return a different result every time it is trained. This means that to ensure that a neural network has a good set of hyperparameters to give accurate results reliably, it must be retrained many times, and its results averaged to determine its actual performance. It is not uncommon in physical science applications where producing reliable results is essential to use a "forest" of 100 identical neural networks and use the average results, the true answer, and the standard deviation across all the predictions as the uncertainty of the result \cite{Ref6}.

