In this chapter and the previous one, we have developed the computational framework needed for this thesis. First, we explored several supervised machine learning algorithms, and then we used these algorithms to develop the sequential regression extrapolation (SRE) algorithm. Though we have developed the SRE algorithm to work with any supervised machine learning algorithm, in practice, we will restrict ourselves to only using three in the following two results chapters: ridge regression, Bayesian ridge regression, and Gaussian processes. Several reasons for not using neural networks or recurrent neural networks for this application have been given in this chapter and the previous one. Though kernel ridge regression does perform well as the machine learning algorithm in an SRE analysis, a large amount of hyperparameters KRR has makes it unattractive. Many-body calculations are very time-consuming; thus, avoiding the need to generate a validation data set is optimal.
Furthermore, suppose we wish to develop a machine learning extrapolation algorithm that is both accurate and saves time. In that case, the time costs of generating a validation data set and performing an extensive tuning process over many hyperparameters are unattractive. Thus neural networks, recurrent neural networks, and kernel ridge regression are eliminated as possible algorithms.

The following two chapters will apply the methods we have developed in this chapter to coupled cluster calculations of infinite nuclear matter calculations. Chapter 7 will focus on calculations of the homogeneous electron gas, and Chapter 8 will focus on calculations of infinite nuclear matter; pure neutron matter and symmetric nuclear matter will be analyzed.