


Removing the basis incompleteness and finite size errors by formatting it as an extrapolation problem is a promising application of machine learning because it is well formatted. Furthermore, the extrapolations are known to have asymptotic values for the correlation energies (i.e., the converged values), there is a simple pattern in the data for the machine learning to pick up, and the training data is already near the converged values (but still far enough away that performing the extrapolation increases the accuracy of the results) \cite{Ref6}.

Attempting to remove basis incompleteness and finite size errors from many-body calculations with machine learning is not a novel idea. For example, in Ref \cite{Ref6}, the authors attempt to use a neural network to perform an extrapolation to remove the basis incompleteness error for a harmonic oscillator basis used in coupled cluster calculations of nuclei. However, the authors encountered the problems that would be expected when using neural networks for this application, including difficulty working with small data sets (leading to the need for interpolation before extrapolation) and neural network's inability to create exactly reproducible results due to its training process \cite{Ref6}. Another example of using machine learning to remove truncation errors from many-body calculations can be found in ADD MORE HERE. However, further examples can be found in Refs. \cite{ADD NUMBER} through \cite{ADD NUMBER}.

We should point out that other methods exist to eliminate the finite size errors other than performing calculations at higher N or extrapolating. One of these options is to use twisted boundary conditions instead of periodic boundary conditions, which provide much more accurate estimates of the correlation energies \cite{Ref4}.