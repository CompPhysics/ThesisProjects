<!--
Automatically generated HTML file from DocOnce source
(https://github.com/hplgit/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/hplgit/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Quantum Boltzmann Machines">

<title>Quantum Boltzmann Machines</title>


<style type="text/css">
/* bloodish style */

body {
  font-family: Helvetica, Verdana, Arial, Sans-serif;
  color: #404040;
  background: #ffffff;
}
h1 { font-size: 1.8em;  color: #8A0808; }
h2 { font-size: 1.6em;  color: #8A0808; }
h3 { font-size: 1.4em;  color: #8A0808; }
h4 { color: #8A0808; }
a { color: #8A0808; text-decoration:none; }
tt { font-family: "Courier New", Courier; }
/* pre style removed because it will interfer with pygments */
p { text-indent: 0px; }
hr { border: 0; width: 80%; border-bottom: 1px solid #aaa}
p.caption { width: 80%; font-style: normal; text-align: left; }
hr.figure { border: 0; width: 80%; border-bottom: 1px solid #aaa}

div { text-align: justify; text-justify: inter-word; }
</style>


</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Quantum Computing and Machine Learning', 2, None, '___sec0'),
              ('Thesis Project', 2, None, '___sec1'),
              ('Specific tasks and milestones', 3, None, '___sec2'),
              ('Literature', 3, None, '___sec3')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "AMS"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



    
<!-- ------------------- main content ---------------------- -->



<center><h1>Quantum Boltzmann Machines </h1></center>  <!-- document title -->

<p>
<!-- author(s): Master of Science thesis project -->

<center>
<b>Master of Science thesis project</b> 
</center>

<p>
<!-- institution(s) -->

<br>
<p>
<center><h4>Dec 1, 2020</h4></center> <!-- date -->
<br>

<h2 id="___sec0">Quantum Computing and Machine Learning </h2>

<p>
<b>Quantum Computing and Machine Learning</b> are two of the most promising
approaches for studying complex physical systems where several length
and energy scales are involved.  Traditional many-particle methods,
either quantum mechanical or classical ones, face huge dimensionality
problems when applied to studies of systems with many interacting
particles. To be able to define properly effective potentials for
realistic molecular dynamics simulations of billions or more particles,
requires both precise quantum mechanical studies as well as algorithms
that allow for parametrizations and simplifications of quantum
mechanical results. Quantum Computing offers now an interesting
avenue, together with traditional algorithms, for studying complex
quantum mechanical systems. Machine Learning on the other hand allows us to parametrize
these results in terms of classical interactions. These interactions
are in turn suitable for large scale molecular dynamics simulations of
complicated systems spanning from subatomic physics to materials
science and life science.

<h2 id="___sec1">Thesis Project </h2>

<p>
Boltzmann Machines (BMs) offer a powerful framework for modelling
probability distributions.  These types of neural networks use an
undirected graph-structure to encode relevant information.  More
precisely, the respective information is stored in bias coefficients
and connection weights of network nodes, which are typically related
to binary spin-systems and grouped into those that determine the
output, the visible nodes, and those that act as latent variables, the
hidden nodes.

<p>
Furthermore, the network structure is linked to an energy function
which facilitates the definition of a probability distribution over
the possible node configurations by using a concept from statistical
mechanics, i.e., Gibbs states.  The aim of BM training is to learn a
set of weights such that the resulting model approximates a target
probability distribution which is implicitly given by training data.
This setting can be formulated as discriminative as well as generative
learning task.  Applications have been studied in a large variety of
domains such as the analysis of quantum many-body systems, statistics,
biochemistry, social networks, signal processing and finance

<p>
However, BMs are complicated to train in practice because the loss
function's derivative requires the evaluation of a normalization
factor, the partition function, that is generally difficult to
compute.  Usually, it is approximated using Markov Chain Monte Carlo
methods which may require long runtimes until convergence

<p>
Quantum Boltzmann Machines (QBMs) are a natural adaption of BMs to the quantum computing framework. Instead of an energy function with nodes being represented by binary spin values, QBMs define the underlying network using a Hermitian operator, a parameterized Hamiltonian

$$
\begin{equation*}
    H_{\theta}=\sum_{i=0}^{p-1}\theta_ih_i,
\end{equation*}
$$

<p>
with \( \theta\in\mathbb{R}^p \) and \( h_i=\bigotimes_{j=0}^{n-1}\sigma_{j, i} \) for \( \sigma_{j, i}\in\set{I, X, Y, Z} \) acting on the \( j^{\text{th}} \) qubit.

<p>
The network nodes are hereby characterized by the Pauli matrices \( \sigma_{j, i} \).

<h3 id="___sec2">Specific tasks and milestones  </h3>

<p>
The aim of this thesis is to study the implementation of

<p>
The thesis is expected to be handed in May/June 2022.

<h3 id="___sec3">Literature </h3>

<ol>
<li> Amin et al., <b>Quantum Boltzmann Machines</b>, Physical Review X <b>8</b>, 021050 (2018).</li>
<li> Zoufal et al., <b>Variational Quantum Boltzmann Machines</b>, ArXiv:2006.06004.</li>
<li> Maria Schuld and Francesco Petruccione, <b>Supervised Learning with Quantum Computers</b>, Springer, 2018</li>
</ol>


<!-- ------------------- end of main content --------------- -->


</body>
</html>
    

