<!--
Automatically generated HTML file from DocOnce source
(https://github.com/hplgit/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/hplgit/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Machine Learning: Bayesian Machine Learning">

<title>Machine Learning: Bayesian Machine Learning</title>


<style type="text/css">
/* bloodish style */

body {
  font-family: Helvetica, Verdana, Arial, Sans-serif;
  color: #404040;
  background: #ffffff;
}
h1 { font-size: 1.8em;  color: #8A0808; }
h2 { font-size: 1.6em;  color: #8A0808; }
h3 { font-size: 1.4em;  color: #8A0808; }
h4 { color: #8A0808; }
a { color: #8A0808; text-decoration:none; }
tt { font-family: "Courier New", Courier; }
/* pre style removed because it will interfer with pygments */
p { text-indent: 0px; }
hr { border: 0; width: 80%; border-bottom: 1px solid #aaa}
p.caption { width: 80%; font-style: normal; text-align: left; }
hr.figure { border: 0; width: 80%; border-bottom: 1px solid #aaa}

div { text-align: justify; text-justify: inter-word; }
</style>


</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Bayesian Machine Learning, Level Densities and Probability',
               2,
               None,
               '___sec0'),
              ('Thesis Projects', 2, None, '___sec1'),
              ('Specific tasks and milestones', 3, None, '___sec2'),
              ('References', 3, None, '___sec3')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "AMS"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



    
<!-- ------------------- main content ---------------------- -->



<center><h1>Machine Learning: Bayesian Machine Learning</h1></center>  <!-- document title -->

<p>
<!-- author(s): Master of Science thesis project -->

<center>
<b>Master of Science thesis project</b> 
</center>

<p>
<!-- institution(s) -->

<br>
<p>
<center><h4>Nov 28, 2019</h4></center> <!-- date -->
<br>

<h2 id="___sec0">Bayesian Machine Learning, Level Densities and Probability  </h2>

<p>
The level density \( \rho(E) \) as function of energy \( E \) plays a central in many
physics applications, ranging from the modeling of nuclear
astrophysics reactions central to the synthesis of the elements to the
classification and understanding of phases in condensed matter
physics.

<p>
In statistical physics it defines the thermodynamical potential in the micro-canonical ensembler and thereby the entropy as
$$
S(E) = -k_B \ln{(\rho(E))},
$$

and the partition function \( Z(\beta) \) (with \( \beta = 1/k_BT \))  as
$$
Z(\beta) = \int dE \exp{(-\beta E)}\rho(E),
$$

and the expectation values of various moments of the energy
as
$$
\mathbb{E}^n(\beta) = \frac{\int dE E^n\exp{(-\beta E)}\rho(E)}{Z(\beta)}. 
$$

We can rewrite this equation as
$$
\mathbb{E}^n(\beta) = \int dE E^n P(E\vert\beta), 
$$

<p>
where \( P(E\vert\beta) \) is the likelihood of being in a state with
energy \( E \) with temperature \( \beta \). The probability is defined as

$$
P(E\vert\beta) = \frac{\exp{(-\beta E)}\rho(E)}{Z(\beta)}. 
$$

<p>
With the density of states we can in turn define a probability distribution function (PDF) in say for example the canonical ensemble. Alternatively, if we have the PDF we can find the denisty of states.

<h2 id="___sec1">Thesis Projects </h2>

<p>
The aim of this thesis project is employ Bayesian machine learning to
define a PDF, either from experiment or from theoretical simulations.
Eventually, based on the PDF, can attempt to define a a level density
\( \rho(E) \), or the other way around. The first step is to use an
already available model for extracting the level density from exact
diagonalization. These data will then be used to define a posterior
distribution based on a Bayesian machine learning approach.

<h3 id="___sec2">Specific tasks and milestones  </h3>

<p>
The projects can easily be split into several parts and form the basis for collaborations among several students. The milestones are as follows

<ol>
<li> Spring 2020:</li> 
<li> Fall 2020:</li> 
<li> Spring 2021:</li> 
</ol>

The thesis is expected to be handed in May/June  2021.

<h3 id="___sec3">References </h3>

<p>
Highly relevant articles for possible thesis projects are:

<!-- ------------------- end of main content --------------- -->


</body>
</html>
    

