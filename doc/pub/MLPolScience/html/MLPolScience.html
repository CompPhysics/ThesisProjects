<!--
Automatically generated HTML file from DocOnce source
(https://github.com/hplgit/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/hplgit/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Machine learning on legislative text in EU and EU countries to provide a quantitative backbone">

<title>Machine learning on legislative text in EU and EU countries to provide a quantitative backbone</title>


<style type="text/css">
/* bloodish style */

body {
  font-family: Helvetica, Verdana, Arial, Sans-serif;
  color: #404040;
  background: #ffffff;
}
h1 { font-size: 1.8em;  color: #8A0808; }
h2 { font-size: 1.6em;  color: #8A0808; }
h3 { font-size: 1.4em;  color: #8A0808; }
h4 { color: #8A0808; }
a { color: #8A0808; text-decoration:none; }
tt { font-family: "Courier New", Courier; }
/* pre style removed because it will interfer with pygments */
p { text-indent: 0px; }
hr { border: 0; width: 80%; border-bottom: 1px solid #aaa}
p.caption { width: 80%; font-style: normal; text-align: left; }
hr.figure { border: 0; width: 80%; border-bottom: 1px solid #aaa}

div { text-align: justify; text-justify: inter-word; }
</style>


</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Machine learning in Political Science', 2, None, '___sec0'),
              ('References', 3, None, '___sec1')]}
end of tocinfo -->

<body>

    
<!-- ------------------- main content ---------------------- -->



<center><h1>Machine learning on legislative text in EU and EU countries to provide a quantitative backbone</h1></center>  <!-- document title -->

<p>
<!-- author(s): Master of Science thesis project -->

<center>
<b>Master of Science thesis project</b> 
</center>

<p>
<!-- institution(s) -->

<br>
<p>
<center><h4>Dec 25, 2018</h4></center> <!-- date -->
<br>

<h2 id="___sec0">Machine learning in Political Science  </h2>

<p>
Survey data, the engine of the behavioral revolution of the social
sciences is about to run its course, with low response rate and poorly
representative samples being the norm rather than the
exception. Fortunately, vast amount of new information from social
media, via digitalized governmental archives, to population registries
are opening up new exiting avenues for innovative social science
research, such as paternity leave and children&#8217;s performance in
school, extent of censorship in Chinese online new reporting, or
conditions for receptiveness to fake news. Moreover, the new data
availability in combination with tools from machine-learning has
spurred an interest in prediction and sophisticated
policy-recommendations, ranging from optimize relocation of immigrants
given their skill-set and local labor market needs, via probabilistic
detection of election fraud, to forecasting of popular unrest and
civil war. The undertaking of such research questions was, until
recently, outside the realm of social science. There are however
limits to the amount of new insights that can be obtained purely from
richer data and &#8220;black-box&#8221; import of machine-learning tools. More
robust, new insights require similar steps to be taken in the
development of applied, testable, theoretical models to facilitate
direct empirical evaluations of the model dynamics and the consistency
of the model with the data. Such a step requires a solid grounding in
computing.

<p>
The aim of the project is to develop an algorithm based on Machine
Learning methods to help determine where EU directives and regulations
originate from. The download/upload model states that part of the
legislative process in the EU is member countries <em>uploading</em> parts of
their existing national body of legislation to be incorporated to the
EU legislation.  If this is the case one should be able to identify
parts of the native legislative texts from their country of origin in
the EU-legislation. Based on this a machine learning algorithm will be
implemented to compare and examine legislative texts.

<p>
By taking as input the national legislation of the countries before an
EU regulation is made, and the finished EU-regulation, and search for
similarities, for instance how much of the respective countries
national legislation is to be found in the EU regulation, one can use
this as a proxy for assessing which country or countries has the most
influence on the resulting regulation. As all EU-laws are translated
to all languages in the EU, language differences does not need to be
taken into consideration.

<p>
It is expected to find various levels of what Padgett calls <a href="http://www.int.washington.edu/PROGRAMS/17-66W/" target="_blank">synthesis
and emulation</a> [1] (meaning mixes of several states,
synthesis, or more or less copying from one state, emulation),
depending of what field one has to consider, but what is said about
this earlier is qualitative and inconsistent, so this quantitative
approach might serve as a backbone for further research.

<p>
To evaluate this model one can follow the similarities into the
download-phase, where the countries of the EU have to implement the
laws following the guidelines set by the directive and see to what
degree the member countries follow it. That is, how compliant the
country is, which is a subject that has been more studied and thus
have more material to compare with. So one can see if this method can
replicate the findings of various articles written on the compliance
of EU countries to EU law [2-5].

<p>
When this is done, I will look at how these factors change over time,
to see if the dominant countries become more dominant or less, or if
they change.

<p>
The milestones are as follows

<ol>
<li> Spring 2019: Develop, based on recurrent neural networks, reiforcement learning  and autoencoders [6], code and theory for analyzing text. In particular, develop code with the aim to extract specific phrases and sentences.</li> 
<li> Fall 2019: Start including selected texts from the EU and apply the above Machine Learning techniques to these. Start analyzing the data.</li>
<li> Spring 2020: Final analysis of data and wrap up of thesis.</li> 
</ol>

The thesis is expected to be handed in May/June  2020.

<h3 id="___sec1">References </h3>

<ol>
<li> Stephen   Padgett, <em>Between synthesis and emulation: EU policy transfer in the power sector</em>, Journal of European Public Policy <b>10</b>, 227 (2003).</li>
<li> Dimiter Toshkov, <em>Embracing European Law: Compliance with EU Directives in Central and Eastern Europe</em>, European Union Politics <b>9</b>, 379 (2008).</li>
<li> Tanja A. Borzel, <em>Why there is no southern problem. On environmental leaders and laggards in the European Union</em>, Journal of European Public Policy <b>7</b>, 141 (2000).</li>
<li> Dimiter Toshkov, <em>In search of the worlds of compliance: culture and transposition performance in the European Union</em>, Journal of European Public Policy <b>14</b>, 933 (2007).</li>
<li> Eva Thomann and Asya Zhelyazkova, <em>Moving beyond (non-)compliance: the customization of European Union policies in 27 countries</em>, Journal of European Public Policy <b>24</b>, 1269 (2017).</li> 
<li> Aurelien Geron, <em>Hands-on Machine Learning with Scikit-Learn and TensorFlow</em>, O'Reilly, 2017.</li>
</ol>


<!-- ------------------- end of main content --------------- -->


</body>
</html>
    

